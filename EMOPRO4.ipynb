{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I have a GPU?  False\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\" I have a GPU? \", use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. smaller architecture\n",
    "\n",
    "## 2. validation set\n",
    "\n",
    "## 3. validation evaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\npairs = [\\n['sad','depression'],    \\n['lonely','depression'],\\n['stress','anxiety'],\\n['happy','happy'],\\n['love','happy'],    \\n]\\n\\n\\n\\nnew_pairs = []\\nfor pair in pairs:\\n    if len(pair[0]) > 300 and len(pair[0]) < 310:\\n        new_pairs.append(pair)\\npairs = new_pairs\\nlen(pairs)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a Character Level RNN, it used the most common symbols and the upper and lower case Letters\n",
    "\n",
    "char2idx, idx2char, character_list = pickle.load( open( \"data/characters.p\", \"rb\" ) )\n",
    "\n",
    "pairs = pickle.load( open( \"data/8pairs_50_1000.p\", \"rb\" ) ) \n",
    "\n",
    "print(len(pairs))\n",
    "\n",
    "training_pairs = pairs[:25000]\n",
    "validation_pairs = pairs[25000:]\n",
    "\n",
    "class2index = {\n",
    " 'addiction': 2,\n",
    " 'anxiety': 4,\n",
    " 'autism': 0,\n",
    " 'bipolar': 7,\n",
    " 'conversation': 3,\n",
    " 'depression': 6,\n",
    " 'happy': 5,\n",
    " 'schizophrenia': 1,\n",
    "}\n",
    "\n",
    "index2class =  {v: k for k, v in class2index.items()}\n",
    "\n",
    "''' \n",
    "pairs = [\n",
    "['sad','depression'],    \n",
    "['lonely','depression'],\n",
    "['stress','anxiety'],\n",
    "['happy','happy'],\n",
    "['love','happy'],    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "new_pairs = []\n",
    "for pair in pairs:\n",
    "    if len(pair[0]) > 300 and len(pair[0]) < 310:\n",
    "        new_pairs.append(pair)\n",
    "pairs = new_pairs\n",
    "len(pairs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(sentence):\n",
    "    '''\n",
    "     | is our end of sentence character \n",
    "     ~ is our start of sentence character\n",
    "     if these occur naturally in our string, replace it with our unknown character\n",
    "     _ is our unknown character\n",
    "    '''\n",
    "    sentence_as_indices = []\n",
    "    sentence = sentence.replace(\"|\",\"_\")\n",
    "    sentence = sentence.replace(\"~\",\"_\")\n",
    "    for char in sentence:\n",
    "        if char in char2idx:\n",
    "            sentence_as_indices.append(char2idx[char])\n",
    "        else:\n",
    "            sentence_as_indices.append(char2idx[\"_\"])\n",
    "            \n",
    "    sentence_as_indices.append(char2idx[\"|\"])\n",
    "    \n",
    "    return sentence_as_indices\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad a with the PAD symbol\n",
    "def pad_seq(seq, max_length):\n",
    "    seq += [char2idx[\" \"] for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "def random_batch(batch_size):\n",
    "    input_seqs = []\n",
    "    targets = []\n",
    "\n",
    "    # Choose random pairs\n",
    "    for i in range(batch_size):\n",
    "        #pair = random.choice(pairs)\n",
    "        pair = random.choice(training_pairs)\n",
    "        input_seqs.append(indexesFromSentence(pair[0]))\n",
    "        targets.append(class2index[pair[1]])\n",
    "\n",
    "    # Zip into pairs, sort by length (descending), unzip\n",
    "    #seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    #input_seqs, target_seqs = zip(*seq_pairs)\n",
    "    \n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "    #target_lengths = [len(s) for s in target_seqs]\n",
    "    #target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    #target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n",
    "    targets = Variable(torch.LongTensor(targets))\n",
    "    \n",
    "    if use_cuda:\n",
    "        input_var = input_var.cuda()\n",
    "        targets = targets.cuda()\n",
    "        \n",
    "    return input_var, input_lengths, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   14     0\n",
       "   81    49\n",
       "   41    50\n",
       "   48    38\n",
       "   44    50\n",
       "   81    81\n",
       "   42    28\n",
       "   49    30\n",
       "   51    81\n",
       "   39    45\n",
       "   27    30\n",
       "   51    43\n",
       "   39    81\n",
       "   46    42\n",
       "   81    49\n",
       "   48    51\n",
       "   33    39\n",
       "   30    27\n",
       "   43    81\n",
       "   42    36\n",
       "   81    30\n",
       "   32    44\n",
       "   43    42\n",
       "   36    81\n",
       "   26    30\n",
       "   51    35\n",
       "   39    81\n",
       "   46    45\n",
       "   81    30\n",
       "   30    43\n",
       "   35    38\n",
       "   35    81\n",
       "   81    48\n",
       "   42    39\n",
       "   49    29\n",
       "   51    51\n",
       "   44    50\n",
       "   81    42\n",
       "   33    45\n",
       "   38    81\n",
       "   51    47\n",
       "   28    30\n",
       "   46    36\n",
       "   50    50\n",
       "   55    44\n",
       "   81    81\n",
       "   14    35\n",
       "   42    38\n",
       "   81    30\n",
       "   47    36\n",
       "   48    56\n",
       "   36    81\n",
       "   50     2\n",
       "   81    39\n",
       "   43    28\n",
       "   26    81\n",
       "   81    51\n",
       "   50    35\n",
       "   48    81\n",
       "   38    45\n",
       "   40    30\n",
       "   45    43\n",
       "   81    81\n",
       "   30    41\n",
       "   39    48\n",
       "   81    39\n",
       "   36    42\n",
       "   50    81\n",
       "   81    42\n",
       "   48    30\n",
       "   39    81\n",
       "   28    48\n",
       "   81    39\n",
       "   14    44\n",
       "   81    41\n",
       "   32    50\n",
       "   43    38\n",
       "   44    81\n",
       "   42    42\n",
       "   81    49\n",
       "   27    51\n",
       "   51    44\n",
       "   39    81\n",
       "   28    48\n",
       "   48    44\n",
       "   81    81\n",
       "   28    41\n",
       "   38    50\n",
       "   30    40\n",
       "   31    40\n",
       "   50    54\n",
       "   81    81\n",
       "   26    41\n",
       "   48    49\n",
       "   44    48\n",
       "   42    42\n",
       "   81    81\n",
       "   51    28\n",
       "   42    30\n",
       "   55    81\n",
       "   81    45\n",
       "   14    30\n",
       "   81    43\n",
       "   35    81\n",
       "   50    28\n",
       "   50    30\n",
       "   40    81\n",
       "   81    48\n",
       "   41    33\n",
       "   50    30\n",
       "   51    43\n",
       "   38    42\n",
       "   28    81\n",
       "   60    51\n",
       "   81    42\n",
       "   81    81\n",
       "   81    41\n",
       "   81    49\n",
       "   81    50\n",
       "   81    39\n",
       "   81    81\n",
       "   81    51\n",
       "   81    42\n",
       "   81    81\n",
       "   81    47\n",
       "   81    30\n",
       "   81    36\n",
       "   81    50\n",
       "   81    44\n",
       "   81    56\n",
       "   81    60\n",
       "[torch.LongTensor of size 131x2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_var, input_lengths, targets = random_batch(2)\n",
    "input_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49, 51, 81, 104, 81, 45, 30, 43, 60]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexesFromSentence(\"hi ` you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers = 3, bidirectional = False, dropout=0.1):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers, \n",
    "                          dropout=self.dropout, bidirectional=bidirectional)\n",
    "        \n",
    "        if bidirectional:\n",
    "            num_directions = 2\n",
    "        else:\n",
    "            num_directions = 1\n",
    "        \n",
    "        hidden0 = torch.zeros(self.num_layers*num_directions, 1, self.hidden_size)\n",
    "        self.hidden0 = nn.Parameter(hidden0, requires_grad=True)\n",
    "\n",
    "    def forward(self, input_seqs):\n",
    "        \n",
    "        # expects inputs of shape [torch.cuda.LongTensor of size seq_length x batch_size ]\n",
    "        \n",
    "        if use_cuda:\n",
    "            input_seqs.cuda()\n",
    "            \n",
    "        batch_size = input_seqs.size(1)\n",
    "        hidden = self.hidden0.repeat(1, batch_size, 1)\n",
    "        self.embedded = self.embedding(input_seqs)\n",
    "        output, hidden = self.gru(self.embedded, hidden)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            # Sum bidirectional outputs\n",
    "            output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:] \n",
    "          \n",
    "        return output, hidden  # hidden.shape = [layers x directions, batch_size, hidden_size]\n",
    "    \n",
    "    def initHidden(self):\n",
    "        \n",
    "        if use_cuda:\n",
    "            return self.hidden0.cuda()\n",
    "        else:\n",
    "            return self.hidden0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, example_encoder_hidden_state, num_classes,vector_size):\n",
    "        \n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        # hidden.shape = [layers x directions, batch_size, hidden_size]\n",
    "        # num_cells = layers x directions\n",
    "        num_cells, batch_size, hidden_size = encoder_hidden.shape\n",
    "        self.num_cells = num_cells\n",
    "        self.batch_size = batch_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.vector_size = vector_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_cells*hidden_size,vector_size)\n",
    "        self.fc2 = nn.Linear(vector_size,num_classes)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, encoder_hidden):\n",
    "        \n",
    "        # when using a linear transformation the first axis should be batch \n",
    "        encoding_batch = encoder_hidden.view(-1,num_cells*hidden_size)\n",
    "        vector_rep = self.prelu(self.fc1(encoding_batch))\n",
    "        output = self.fc2(vector_rep)\n",
    "        \n",
    "        return output, vector_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_batches, input_lengths, targets, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches)\n",
    "    outputs, vector_rep = decoder(encoder_hidden)\n",
    "    # Loss calculation and backpropagation\n",
    "    loss = criterion(outputs,targets)\n",
    "    \n",
    "    #print(loss)\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] #, ec, dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2 512\n"
     ]
    }
   ],
   "source": [
    "num_layers_encoder = 3\n",
    "bidirectional = True\n",
    "num_chars = len(char2idx)\n",
    "hidden_size = 512\n",
    "batch_size = 2\n",
    "dropout = 0.0\n",
    "vector_size = 256\n",
    "\n",
    "encoder = EncoderRNN( num_chars, hidden_size, num_layers = num_layers_encoder, \n",
    "                     bidirectional = bidirectional, dropout = dropout)\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "\n",
    "input_batch, input_lengths, targets = random_batch(batch_size)\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder(input_batch)\n",
    "\n",
    "num_cells, batch_size, hidden_size = encoder_hidden.shape\n",
    "print(num_cells, batch_size, hidden_size)\n",
    "\n",
    "decoder = DecoderRNN(encoder_hidden,len(class2index),vector_size)\n",
    "if use_cuda:\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "name = \"_emo2_encode3L512_affine_256_bi_cpu\"\n",
    "\n",
    "encoder.load_state_dict(torch.load(\"modelstate/encoder\"+name+\".pth\"))\n",
    "decoder.load_state_dict(torch.load(\"modelstate/decoder\"+name+\".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4m 2s (- 804m 16s) (2 0%) 2.4334\n",
      "val acc:  0.0\n",
      "7m 35s (- 751m 2s) (4 1%) 1.6498\n",
      "val acc:  0.05\n",
      "12m 21s (- 811m 51s) (6 1%) 2.3029\n",
      "val acc:  0.05\n",
      "15m 25s (- 755m 27s) (8 2%) 1.6697\n",
      "val acc:  0.05\n",
      "96m 1s (- 3744m 41s) (10 2%) 1.6317\n",
      "val acc:  0.1\n",
      "100m 16s (- 3242m 3s) (12 3%) 2.9125\n",
      "val acc:  0.15\n",
      "103m 33s (- 2855m 7s) (14 3%) 0.9803\n",
      "val acc:  0.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-2afa9beca16e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Run the train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     loss = train(input_batches, input_lengths, targets, encoder, decoder,\n\u001b[0;32m---> 37\u001b[0;31m                  encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Keep track of loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2200d2a01d01>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_batches, input_lengths, targets, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Update parameters with optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "\n",
    "# configure training # good params for the dummy set are bs = 4, 80 epochs, printevery 4, gamma = 0.9, lr = .001\n",
    "batch_size = 4\n",
    "n_epochs = 400\n",
    "epoch = 0\n",
    "print_every = 2 #10\n",
    "gamma = .99\n",
    "learning_rate = 0.001\n",
    "vettedlist = [8,1,12,14,15,21,22,34,36,37,38,45,46,49,56,65,70,71,73,75]\n",
    "# Initialize optimizers and criterion\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(),lr=learning_rate)\n",
    "\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "escheduler = optim.lr_scheduler.StepLR(encoder_optimizer, step_size=print_every, gamma=gamma) \n",
    "\n",
    "dscheduler = optim.lr_scheduler.StepLR(decoder_optimizer, step_size=print_every, gamma=gamma) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    input_batches, input_lengths, targets = random_batch(batch_size)\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_batches, input_lengths, targets, encoder, decoder,\n",
    "                 encoder_optimizer, decoder_optimizer, criterion)\n",
    "    \n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss \n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), \n",
    "                                               epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        input_var, labels = validationBatch(validation_pairs,vettedlist)\n",
    "        val_acc = validationAccuracy(input_var, labels)\n",
    "        print(\"val acc: \",val_acc)\n",
    "        \n",
    "    \n",
    "    escheduler.step()\n",
    "    dscheduler.step()\n",
    "    \n",
    "# 1/8 = 0.125, -ln(1/8) = 2.08\n",
    "name = \"_emo3_encode3L512_affine_256_bi_\"\n",
    "\n",
    "torch.save(encoder.state_dict(), \"modelstate/encoder\"+name+\"cpu.pth\")\n",
    "torch.save(decoder.state_dict(), \"modelstate/decoder\"+name+\"cpu.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"_emo3_encode3L512_affine_256_bi_\"\n",
    "\n",
    "torch.save(encoder.state_dict(), \"modelstate/encoder\"+name+\"cpu.pth\")\n",
    "torch.save(decoder.state_dict(), \"modelstate/decoder\"+name+\"cpu.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2prediction(string):\n",
    "    input_var = indexesFromSentence(string)\n",
    "    input_var = Variable(torch.LongTensor(input_var)).unsqueeze(1) #.transpose(0, 1)#.unsqueeze(0) \n",
    "    if use_cuda:\n",
    "        input_var = input_var.cuda()\n",
    "    #print(input_var)\n",
    "    encoder_outputs, encoder_hidden = encoder(input_var)\n",
    "    #print(encoder_hidden.shape)\n",
    "    outputs, vector_rep = decoder(encoder_hidden)\n",
    "    return index2class[np.argmax(outputs.data.cpu().numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conversation'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"*Phone Rings*\\n\\nMom: Get That. \\n\\nMe: Hello?\\n\\nSister: Hey, what's going on?\\n\\nMe: Oh, just fartin' around.\"\n",
    "string2prediction(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35596026490066224"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "215/604 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {}\n",
    "for pair in validation_pairs:\n",
    "    if pair[1] in count_dict:\n",
    "        count_dict[pair[1]] += 1\n",
    "    else:\n",
    "        count_dict[pair[1]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addiction': 36,\n",
       " 'anxiety': 60,\n",
       " 'autism': 13,\n",
       " 'bipolar': 56,\n",
       " 'conversation': 215,\n",
       " 'depression': 201,\n",
       " 'happy': 3,\n",
       " 'schizophrenia': 12}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_dict # majority classifier = 215/604 = 0.35596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationBatch(validation_pairs, vettedlist):\n",
    "    \n",
    "    input_seqs = []\n",
    "    targets = []\n",
    "    #for pair in validation_pairs:\n",
    "    for i in vettedlist:\n",
    "        #input_seqs.append(indexesFromSentence(pair[0]))\n",
    "        input_seqs.append(indexesFromSentence(validation_pairs[i][0]))\n",
    "        targets.append(validation_pairs[i][1])\n",
    "        \n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "\n",
    "    if use_cuda:\n",
    "        input_var = input_var.cuda()\n",
    "        \n",
    "    labels = []\n",
    "    for target in targets:\n",
    "        labels.append(class2index[target])\n",
    "        \n",
    "    return input_var, labels\n",
    "\n",
    "def validationAccuracy(input_var, labels):\n",
    "        \n",
    "    encoder_outputs, encoder_hidden = encoder(input_var)\n",
    "    outputs, vector_rep = decoder(encoder_hidden)\n",
    "    predictions = np.argmax(outputs.data.cpu().numpy(),axis=1)\n",
    "    correct = np.array(labels) == predictions \n",
    "    correct =  correct + 0\n",
    "    return np.sum(correct)/np.size(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vettedlist = [8,1,12,14,15,21,22,34,36,37,38,45,46,49,56,65,70,71,73,75]\n",
    "input_var, labels = validationBatch(validation_pairs,vettedlist)\n",
    "val_acc = validationAccuracy(input_var, labels)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
